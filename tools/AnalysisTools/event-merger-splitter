#!/usr/bin/env python

from __future__ import print_function

import datetime as dt
import gzip
import heapq
import os
import signal
import subprocess
import sys

import functools as ft
import itertools as it

try:
    import ujson as json
except:
    import json

VERBOSE = False

#############################################
#  Merging 
#############################################
def open_gzip(fname, silent=False):
    if silent:
        preexec_fn = lambda: signal.signal(signal.SIGPIPE, signal.SIG_DFL) # Silence broken pipe warnings
    else:
        preexec_fn = None
    p = subprocess.Popen(["zcat", "-q", fname], stdout = subprocess.PIPE, preexec_fn=preexec_fn)
    return p.stdout

def open_file(fname, silent=False):
    if fname.endswith(".gz"):
        return open_gzip(fname, silent)
    else:
        return open(fname, 'r')

class LazyFileIter(object):
    '''Caches the first line of the file on object creation and does
    not re-open the file until the second line is requested. 
    '''

    def __init__(self, filename):
        self._filename = filename.strip()
        self._readfirst = False
        self._file = None

        with open_file(self._filename, silent=True) as f:
            self._firstline = f.readline()

    def __iter__(self):
        return self

    def next(self):
        if self._readfirst:
            if self._file == None:
                self._file = open_file(self._filename)
                self._file.next() #skip already-returned first line
                if VERBOSE:
                    print("Opened file %s"%self._filename, file=sys.stderr)
            try:
                return self._file.next()
            except StopIteration as e:
                self._file.close()
                if VERBOSE:
                    print("Closed file %s"%self._filename, file=sys.stderr)
                raise e
        else:
            self._readfirst = True
            return self._firstline

@ft.total_ordering # Requires Python 2.7+/3.2+
class ComparableEvent(object):
    
    def __init__(self, encoded):
        self.json = encoded
        data = json.loads(encoded)
        self.seconds = data['time']['sec']
        self.timestamp = self.seconds * 1000000 + data['time']['usec'] 

    def __eq__(self, other):
        return self.timestamp == other.timestamp

    def __lt__(self, other):
        return self.timestamp < other.timestamp

def merge(istreams):
    cmp_streams = [it.imap(ComparableEvent, stream) for stream in istreams]
    sorted_stream = heapq.merge(*cmp_streams)
    return sorted_stream

#############################################
#  Splitting 
#############################################
def parse_date(seconds):
    return dt.datetime.utcfromtimestamp(int(seconds))

def filename_from_date(path, date):
    TEMPLATE = '%s.json.gz'
    return os.path.join(path, TEMPLATE%(date.strftime('%Y-%m-%d')))

LAST_TIMESTAMP = None
LAST_FILENAME = None
def filename_from_timestamp(path, seconds):
    global LAST_TIMESTAMP
    global LAST_FILENAME
    if seconds != LAST_TIMESTAMP:
        LAST_TIMESTAMP = seconds
        LAST_FILENAME = filename_from_date(path,parse_date(seconds))
    return LAST_FILENAME

FILENAME = ''
FILE = None

def get_file(path, seconds):
    global FILENAME
    global FILE
    key = filename_from_timestamp(path, seconds)
    if FILENAME != key:
        if (FILE != None):
            FILE.close()
            if VERBOSE:
                print("Closed file %s"%FILENAME, file=sys.stderr)
        FILENAME = key
        FILE = gzip.open(key, 'ab')
        if VERBOSE:
            print("Opened file %s"%key, file=sys.stderr)
    return FILE

def split(istream, path):
    for event in istream:
        get_file(path, event.seconds).write(event.json)

def main(istreams, path):
    split(merge(istreams), path)
 
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Merge and split kernel event buffers.")
    parser.add_argument('-v', '--verbose', action='store_true', default=False, help='print messages about progress to stderr')
    parser.add_argument('path', type=str, help='path in which to store the merged and split logs')
    args = parser.parse_args()

    if args.verbose:
        VERBOSE = True

    fstreams = [LazyFileIter(f) for f in sys.stdin]
    istreams = [it.ifilter(lambda l: l != '\n', s) for s in fstreams]

    main(istreams, args.path)
